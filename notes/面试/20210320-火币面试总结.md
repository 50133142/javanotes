#  202103020-火币面试总结

## CAP

### CAP是什么
C 数据一致性（Consistency）： 系统对一个写操作，如果成功，后续读操作必须读到前面成功写的数据；如果失败，后续读操作也必须读不到，对于服务调用者而言：是数据的强一致性
A 服务可用性(availability)： 所有读写请求都会在一定时间响应，可终止、不会一直等待
P 分区容错性(partition)：在网络分区下，被隔离的节点应该都可以提供服务
* 在分布式环境下，降低单个服务处理压力，分区肯定是必要选项，那我们只需考虑数据一致性和服务可用性（2选1），一般情况我们允许一段时间内数据一致性（补偿、冲正措施等）
* eurake满足CA，还是CP，以及其他组件各自满足哪个场景
### 实例
* zookeeper 满足CP
>ZooKeeper是分布式协调服务，它的职责是保证数据
即任何时刻对ZooKeeper的访问请求能得到一致的数据结果，同时系统对网络分割具备容错性；但是它不能保证每次服务请求的可用性
对于Service发现服务而言，宁可返回某服务5分钟之前在哪几个服务器上可用的信息，也不能因为暂时的网络故障而找不到可用的服务器，而不返回任何结果
>，当master节点因为网络故障与其他节点失去联系时，剩余节点会重新进行leader选举。问题在于，选举leader的时间太长，30 ~ 120s, 且选举期间整个zk集群都是不可用的，这就导致在选举期间注册服务瘫痪。
>在云部署的环境下，因网络问题使得zk集群失去master节点是较大概率会发生的事，虽然服务能够最终恢复，但是漫长的选举时间导致的注册长期不可用是不能容忍的
* eurake 满足AP
>Eureka各个节点都是平等的，几个节点挂掉不会影响正常节点的工作，剩余的节点依然可以提供注册和查询服务。
>而Eureka的客户端在向某个Eureka注册或如果发现连接失败，则会自动切换至其它节点，只要有一台Eureka还在，就能保证注册服务可用(保证可用性)，
>只不过查到的信息可能不是最新的(不保证强一致性)。除此之外，Eureka还有一种自我保护机制，
>如果在15分钟内超过85%的节点都没有正常的心跳，那么Eureka就认为客户端与注册中心出现了网络故障，开启自我保护机制，此时会出现以下几种情况：
 1. Eureka不再从注册列表中移除因为长时间没收到心跳而应该过期的服务
 2. Eureka仍然能够接受新服务的注册和查询请求，但是不会被同步到其它节点上(即保证当前节点依然可用)
 3. 当网络稳定时，当前实例新的注册信息会被同步到其它节点中
 
 因此， Eureka可以很好的应对因网络故障导致部分节点失去联系的情况，而不会像zookeeper那样使整个注册服务瘫痪。

### 事务的四个特性：原子性(Atomcity)  、数据一致性(Consistency)、隔离性(Ioslation)、持久化(Durability)；


## eurake和Nacos各自原理是什么、 区别是什么

### eurake原理
* Eureka Server 集群相互之间通过 Replicate 来同步数据，相互之间不区分主节点和从节点，所有的节点都是平等的；集群采用异步方式同步的，所以不保证节点间的状态一定是一致的，不过基本能保证最终状态是一致的
* Eureka Client会默认30s向Eureka Server发送一次心跳，告知Client状态状态可用，在90s Eureka Server没有收到client心跳，server会从注册表中剔除当前client；发送心跳返回获取到最新的服务注册列表，当client缓存和返回的注册信息不同是，Eureka Cilent会自动更新
* Eureka Sever 内部有三层缓存机制来维护整个注册表

* 自我保护机制  （上述已有）

### Nacos
提供服务注册和发现、配置中心管理、动态DSN服务
* Nacos支持CP和AP 模式，
* 健康检查可以服务端、客户端，eurake只有客服端
* eurake超过1000台时，广播模式同步对eurake集群压力很大

#### 初步选型结论
初步结论为：使用Nacos代替Eureka和apollo，主要理由为：
相比与Eureka：
(1)Nacos具备服务优雅上下线和流量管理（API+后台管理页面），而Eureka的后台页面仅供展示，需要使用api操作上下线且不具备流量管理功能。
(2)从部署来看，Nacos整合了注册中心、配置中心功能，把原来两套集群整合成一套，简化了部署维护
(3)从长远来看，Eureka开源工作已停止，后续不再有更新和维护，而Nacos在以后的版本会支持SpringCLoud+Kubernetes的组合，填补 2 者的鸿沟，在两套体系下可以采用同一套服务发现和配置管理的解决方案，这将大大的简化使用和维护的成本。同时来说,Nacos 计划实现 Service Mesh，是未来微服务的趋势
(4)从伸缩性和扩展性来看Nacos支持跨注册中心同步，而Eureka不支持，且在伸缩扩容方面，Nacos比Eureka更优（nacos支持大数量级的集群）。
(5)Nacos具有分组隔离功能，一套Nacos集群可以支撑多项目、多环境。


## feign调用遇见的什么坑吗
* 低版本的多参数 get方式多参数传值，不生效，尽量避免使用get方式，使用post 和 @Requestbody对象传值 
* Feign的重试策略默认设置为 feign.Retryer#NEVER_RETRY ,fegin一般和Rebbion结合使用，rebbion重试次数需要设置为：0 ，不要重试，有的时候我们开发的接口不能保证幂等性， 
>配置首台服务器重试0次 MaxAutoRetries: ${RIBBON.MAXAUTORETRIES}
  配置其他服务器重试0次 MaxAutoRetriesNextServer: ${RIBBON.MAXAUTORETRIESNEXTSERVER}

## mybatis源码中有哪些组件，作用是什么，例如session

## 索引

* 索引建立时已varchar类型，但是传值时：int类型，是否什么生效，如果不生效，为什么不生效
>会将数值隐式转换，存在函数，但是索引失效，但是这个操作会有无法命中索引的风险

## MQ

### MQ使用时重点考虑五个方面

* 丢消息和中断问题    （生产者  MQ  消费者）
1 交换机和队列设置持久化,参数durable:true
``` java
    public TopicExchange orderTopicExchange() {
        return new TopicExchange(ORDER_EXCHANGE_NAME,true,false);
    }
```
2 消费者丢失数据：刚消费到，还没处理，结果进程挂了，或者你的服务重启了，RabbitMQ认为你都消费了，这数据就丢了。或者消费者拿到数据之后挂了。但是mq任务你是消费了，但事实是没有消费的。
  ack机制，把默认自动确认改手动确认，
``` java
# 开启ACK
spring.rabbitmq.listener.direct.acknowledge-mode=manual
spring.rabbitmq.listener.simple.acknowledge-mode=manual
```
3 消息补偿机制
发送消息和接受消息记录日志到DB，发现哪些消费没有消费成功，定时发送告警邮件，启动手动确认机制

* 消息者消费时抛异常了，怎么处理
1 Spring AMQP 提供了非常方便的解决方案：首先，定义死信交换器和死信队列，
最多尝试 5 次（重试 4 次）；并且采取指数退避重试，首次重试延迟 1 秒，第二次 2 秒，以此类推，最大延迟是 10 秒；如果第 4 次重试还是失败，
则使用 RepublishMessageRecoverer 把消息重新投入一个“死信交换器”中，相应发出告警提示处理

2 消费者try catch时 ，自己通过全局redis设置重试了5次，然后不把异常抛出，吃掉异常发出告警提示处理

* 消息的重复消费问题
我们要求我们消费处理的逻辑必须幂等性  

* 微服务下，不能服务要接收到同一个消息， 相同服务多个实例只能一个实例消费，怎么解决
  

### kafka
#### kafka集群下怎么实现数据不丢失
* ack设置-1，会等待所有同步Replica副本(leader和follower)都收到消息后才生offset，但这样增加消息多区，副本同步，网络耗时，降低吞吐量
* 消费者手动提交offset
* Kafka 某个 broker 宕机，然后重新选举 partition 的 leader。大家想想，要是此时其他的 follower 刚好还有些数据没有同步，结果此时 leader 挂了，然后选举某个 follower 成 leader 之后，不就少了一些数据？这就丢了一些数据啊。
  
  生产环境也遇到过，我们也是，之前 Kafka 的 leader 机器宕机了，将 follower 切换为 leader 之后，就会发现说这个数据就丢了。
  
  所以此时一般是要求起码设置如下 4 个参数：
 ``` 
  给 topic 设置 replication.factor 参数：这个值必须大于 1，要求每个 partition 必须有至少 2 个副本。
  在 Kafka 服务端设置 min.insync.replicas 参数：这个值必须大于 1，这个是要求一个 leader 至少感知到有至少一个 follower 还跟自己保持联系，没掉队，这样才能确保 leader 挂了还有一个 follower 吧。
  在 producer 端设置 acks=all：这个是要求每条数据，必须是写入所有 replica 之后，才能认为是写成功了。
  在 producer 端设置 retries=MAX（很大很大很大的一个值，无限次重试的意思）：这个是要求一旦写入失败，就无限重试，卡在这里了。
```

#### kaka多个partition怎么选举
Kafka会在Zookeeper上针对每个Topic维护一个称为ISR（in-sync replica，已同步的副本）的集合，该集合中是一些分区的副本。只有当这些副本都跟Leader中的副本同步了之后，kafka才会认为消息已提交，并反馈给消息的生产者。如果这个集合有增减，kafka会更新zookeeper上的记录。
  如果某个分区的Leader不可用，Kafka就会从ISR集合中选择一个副本作为新的Leader。
  显然通过ISR，kafka需要的冗余度较低，可以容忍的失败数比较高。假设某个topic有f+1个副本，kafka可以容忍f个服务器不可用。
为什么不用少数服从多数的方法

###  rabbitmq的交换机有哪些属性
Name：交换机名称
Durability：是否持久化。如果持久性，则RabbitMQ重启后，交换机还存在
Auto-delete：当所有与之绑定的消息队列都完成了对此交换机的使用后，删掉它
Arguments：扩展参数

## redis
* redis哪有几个种基础数据结构
1 简单动态SDS字符串，reids自己实现的字符串
2 双向无循环列表 linkdelist
3 字典 ，hashtable
4 跳跃表 skiplist  有序集合的底层实现 sortedset 
5 整数集合 intset 
6 压缩列表ziplist 


* redis的分布式锁实现原理，大并发获取锁时那些场景会出现死锁
1  执行setnx命令， 客户端服务器1挂了，没有设置过期时间 ，其他客户端2就获取不到锁，会出现死锁问题
2  设置过期时间了，客户端服务器1挂了，等待超时释放锁， 客户端服务器2和3同时判断超时释放了，服务器2 获取到锁，设置新的过期时间， 
服务器3再把服务器2设置的过期时间修改，设置成自己的过期时间，此时服务2和3都获取到锁；
>死锁问题：通过实践来判断是否过期，如果已经过期，获取到过期时间get(lockKey)，然后getset(lock_timeout)判断是否和get相同，
相同则证明已经加锁成功，因为可能导致多线程同时执行getset(lock_timeout)方法，这可能导致多线程都只需getset后，对于判断加锁成功的线程，



* redis的底层是什么语言写的
Redis 是用 C 语言写的，但是对于Redis的字符串，却不是 C 语言中的字符串（即以空字符’\0’结尾的字符数组），它是自己构建了一种名为 简单动态字符串（simple dynamic string,SDS）的抽象类型，并将 SDS 作为 Redis的默认字符串表示。
* redis的sortSet底层实现
可排序集合，内容使用跳表算法

## 熔断的原理和作用


## 算法 
* 跳表算法
1 redis的sortedset底层实现使用跳表，有序的集合
特点：1  高度越高，效率越好 2 随机化的数据结构  3 新增、删除、单个查找和红黑树效率差不多，范围查找时跳表效果高很多
原因：在跳表中，要查找区间的元素，我们只要定位到两个区间端点在最低层级的位置，然后按顺序遍历元素就可以了，非常高效。
而红黑树只能定位到端点后，再从首位置开始每次都要查找后继节点，相对来说是比较耗时的

* 从1+2+3+4.....+10000 ,用10线程同步执行，怎么实现
* 一个字符串，依次翻转，怎么实现  

##  rpt的项目有哪些
* doubble和springcloud区别
* doubble的实现原理，为什么比springclould性能搞

## error和exception区别
* 两者的共同父类：throwable，
* error异常会导致程序中断，不可恢复，例如：内存泄漏导致的内存溢出OutOfMemoryError，NoClassDefFoundError
* exception是
>它又分为可检查（checked）异常和不检查（unchecked）异常
>checked:在编写代码阶段必须捕获，不然程序会报错，例如：文件找不到，sql，IO等异常，
>unchecked：程序运行时抛出的异常，例如 NullPointerException,ArrayIndexOutOfBoundsExceptin之类

## 项目中链路跟踪使用哪个，原理是什么
zipkin和sleuth   依赖ziplin包即可，里面包含了ziplin和sleuth包
* 原理：traceId通过uuid生成，全局调用链唯一性，在各个服务中的过滤器和拦截器中，设置设置到hander和ThrowLocal中，
* 调用层次和顺序的SpanID和ParentSpanID组合在一起就可以表示一个树形的调用关系，SpanID表示当前为一个调用节点，ParentSpanID表示这个调用节点的父节点
*

## bpmn的点对点模式

## hashmap怎么减少碰撞，hash值是怎么来的
1 通过链表来解决碰撞问题，链表长度大于8时，转变为红黑树结构


## 从1+2+3+4.....+10000 ,用10线程并行执行，怎么实现


## classLocader有哪些 和双亲委派 作用
1  启动类加载器： 加载java核心库 java.*,构造ExtClassLoader和AppClassLoader 
   扩展类加载器：java编写，加载扩展库，如classpath中的jre ，javax.*或者java.ext.dir 指定位置中的类
   应用类加载器: java编写，加载程序所在的目录，如user.dir所在的位置的class
   自动义加载器：java编写,用户自定义的类加载器,可加载指定路径的class文件
   
2 通过委托方式，依次向上问问，加载过没，防止加载同一个.class，保证核心的class文件的安全，不会被篡改，
例如：自动以写了一个String 类，方法一直，里面的逻辑改动，双亲委派保证了一直加载核心的String类，自己写的不会被加载  
