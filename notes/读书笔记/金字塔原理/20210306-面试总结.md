#  面试总结

## 挑重点项目
> 整理清楚，理解透逻辑脉络，如果不行就背熟 


>
##  所以提及的结论，都需要准备好案例或者数据来佐证你的说法，陈述可信
>



## 准备好几个处理过的比较重要技术问题，往往有奇效
* 对销售数据做分表处理；
>原先有销售主表、商品明细表、支付明细表、优惠明细表、收营员明细，都是一张表保存数据的，
>我们都知道索引树高度在3层时查询效率最高，对应数据为2千万左右，我们需要需要考虑分表应对后期的大数量
>1 我引入sharedingshere-jdbc做数据的分表，主表和四个子表各个40张表都是按照组织id分片存储个不同表中，
原理：sql解析、sql路由、sql改写、sql执行、sql结构并归
>2 改到原来的sql，使用分表场景，当前中间查询时会遇见很多坑，例如，查分表时查询参数要是 long类型，多个数据源，需要及时切换数据源，
>  当销售主表和四个子表需要关联查询，怎么配置不出现40个张表的笛卡尔积，
>3 使用sharedingshpere-proxy和sharedingsphere-scaling对单表的老数据无缝迁移到新的各40个分表中
>>sharedingsphere-scaling原理：1：同步基于binlog文件，所以账号需要拥有slave权限 ；  2  scaling会解析binlog日志文件，把数据写到proxy中，然后proxy对数据路由处理写到对应的库和表中
  * 需要注意的坑
> 1、取模的字段类型不允许设置 unsigned 无符号类型，否则全量同步会失败
> 2、全量同步过程中，sharding-proxy如果挂了会导致同步失败，sharding-scaling 不会进行重试，所以重启sharding-proxy前需要检查提交的任务是否同步成功
> 3、如果迁移的数据表很多，建议部署多个sharding-scaling 实例，提高同步的吞吐量
> 4、sharding-scaling如果挂了或者重启了， 增量数据不会进来，需要重新提交同步任务


## 影响最深的bug


## GC项目中的使用案例

> 我们项目一共有二十几个微服务，所有微服务我们都是部署两个实例，为了节省服务器资源，我们一个服务器部署四个实例，服务器使用：阿里云8核64G，
>我们当时存在问题是：微服务部署时都没配置GC参数，核心服务和边缘服务参数都是默认的，导致没有充分利用好服务器资源，
>例如：报表，业务经常需要导出最近半年，一年的全部销售明细数据，导出时经常出现某个实例挂掉
>仓库服务接口处理时延迟时间较长，
### 改进 
1. 默认参数启动时最大堆内存是linux环境内存的1/4,即8g，并行GC收集器，年轻代晋升到老年代经过15次younGC等等，
> 所有服务的新时代和老年代比列为2： -XX:NewRatio=2
> 所有服务eden区和survivor区的比例： -XX:SurvivorRatio=8 
> 不是核心的服务，最小堆内存Xms和Xmx最大堆内存为6g，核心服务 Xms和Xmx设置为12g，Xms和Xmx一样是避免垃圾回收完成时JVM重新分配内存空间
> 仓库服务GC回收期使用CMS: -XX：+UseConcMarkSweepGC,相对并行GC，它的GC回收时间很短，降低些服务处理低延时问题
>